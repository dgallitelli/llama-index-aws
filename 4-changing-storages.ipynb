{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architectural deep dive - Llama-Index on AWS\n",
    "\n",
    "![](./images/llama-index-feed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Bedrock\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding, Models\n",
    "\n",
    "# Model that will be used to generate the embeddings\n",
    "Settings.embed_model = BedrockEmbedding(\n",
    "    model=Models.COHERE_EMBED_MULTILINGUAL_V3, # <---- supports up to 2048 characters per string.\n",
    "    region_name=\"us-west-2\"\n",
    ") \n",
    "# Model that will be used to generate the answer given the most relevant chunks\n",
    "Settings.llm = Bedrock(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\", \n",
    "    region_name=\"us-west-2\",\n",
    "    context_size=200000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Load Data\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "sentence_splitter = SentenceSplitter(chunk_size=250, chunk_overlap=50)\n",
    "# Create the Vectore Store and Index Store in-memory\n",
    "index = VectorStoreIndex.from_documents(documents, transformations=[sentence_splitter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.set_index_id(\"books\")\n",
    "index.storage_context.persist(\"./storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default__vector_store.json image__vector_store.json\n",
      "docstore.json              index_store.json\n",
      "graph_store.json\n"
     ]
    }
   ],
   "source": [
    "!ls storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Chi è Pinocchio?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Secondo le informazioni fornite nel contesto, Pinocchio è un ragazzaccio, un vagabondo e un vero rompicollo, descritto come disubbidiente e svogliato, che invece di andare a scuola va in giro con i compagni a fare lo sbarazzino. Nonostante il burattino inizialmente cerchi di dipingerlo come un gran buon figliuolo, pieno di voglia di studiare e affezionato alla sua famiglia, alla fine ammette che Pinocchio è davvero un ragazzaccio.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dggallit/Documents/GenAI/personal-projects-and-experiments/notebooks/llama-index-learning/data/pinocchio.txt\n",
      "— E chi glielo tirò?\n",
      "\n",
      "— Un suo compagno di scuola: un certo Pinocchio....\n",
      "\n",
      "— E chi è questo Pinocchio? — domandò il burattino facendo lo gnorri.\n",
      "\n",
      "— Dicono che sia un ragazzaccio, un vagabondo, un vero rompicollo.\n",
      "\n",
      "— Calunnie! Tutte calunnie!\n",
      "\n",
      "— Lo conosci tu questo Pinocchio?\n",
      "\n",
      "— Di vista! — rispose il burattino.\n",
      "\n",
      "— E tu, che concetto ne hai? — gli chiese il vecchietto.\n",
      "\n",
      "— A me mi pare un gran buon figliuolo, pieno di voglia di studiare,\n",
      "obbediente, affezionato al suo babbo e alla sua famiglia.... —\n",
      "\n",
      "Mentre il burattino sfilava a faccia fresca tutte queste bugie, si\n",
      "toccò il naso e si accorse che il naso gli era allungato più di un\n",
      "palmo. Allora tutto impaurito cominciò a gridare:\n",
      "\n",
      "— Non date retta, galantuomo, a tutto il bene che ve ne ho detto;\n",
      "perchè conosco benissimo Pinocchio e posso assicurarvi anch'io ch'è\n",
      "davvero un ragazzaccio, un disubbidiente e uno svogliato, e che invece\n",
      "di andare a scuola, va coi compagni a fare lo sbarazzino! —\n",
      "\n",
      "Appena ebbe pronunziate queste parole, il suo naso raccorcì e tornò\n",
      "alla grandezza naturale, come era prima.\n",
      "/Users/dggallit/Documents/GenAI/personal-projects-and-experiments/notebooks/llama-index-learning/data/pinocchio.txt\n",
      "Giunto dinanzi a casa, trovò l'uscio di strada socchiuso. Lo spinse,\n",
      "entrò dentro, e appena ebbe messo tanto di paletto, si gettò a sedere\n",
      "per terra, lasciando andare un gran sospirone di contentezza.\n",
      "\n",
      "Ma quella contentezza durò poco, perchè sentì nella stanza qualcuno che\n",
      "fece:\n",
      "\n",
      "— Crì-crì-crì!\n",
      "\n",
      "— Chi è che mi chiama? — disse Pinocchio tutto impaurito.\n",
      "\n",
      "— Sono io! —\n",
      "\n",
      "Pinocchio si voltò, e vide un grosso grillo che saliva lentamente su su\n",
      "per il muro.\n",
      "\n",
      "— Dimmi, Grillo, e tu chi sei?\n",
      "\n",
      "— Io sono il Grillo-parlante, e abito in questa stanza da più di\n",
      "cent'anni.\n",
      "\n",
      "— Oggi però questa stanza è mia, — disse il burattino — e se vuoi farmi\n",
      "un vero piacere, vattene subito, senza nemmeno voltarti indietro.\n",
      "\n",
      "— Io non me ne anderò di qui, — rispose il Grillo — se prima non ti\n",
      "avrò detto una gran verità.\n",
      "\n",
      "— Dimmela, e spicciati.\n",
      "\n",
      "— Guai a quei ragazzi che si ribellano ai loro genitori, e che\n",
      "abbandonano capricciosamente la casa paterna. Non avranno mai bene in\n",
      "questo mondo; e prima o poi dovranno pentirsene amaramente.\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    file = node.node.metadata['file_path']\n",
    "    text = node.node.text\n",
    "    print(file)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP Phase\n",
    "\n",
    "![](./images/llama-index-feed-mvp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the docker for chromadb\n",
    "!docker run -d --name chromadb -p 5000:8000 -v ./chroma:/chroma/chroma -e IS_PERSISTENT=TRUE -e ANONYMIZED_TELEMETRY=TRUE chromadb/chroma:latest\n",
    "!docker run -d --name redis -p 6379:6379 redis/redis-stack-server:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-chroma llama-index-storage-index-store-redis llama-index-storage-docstore-redis -qU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document stores contain ingested document chunks, which are called `Node` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.docstore.redis import RedisDocumentStore\n",
    "\n",
    "redis_docs = RedisDocumentStore.from_host_and_port(host=\"0.0.0.0\", port=6379, namespace=\"books-docstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index store contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama Index basic RAG example\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "chroma = ChromaVectorStore(host=\"0.0.0.0\", port=5000, collection_name=\"books-vectorstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.index_store.redis import RedisIndexStore\n",
    "\n",
    "redis_index = RedisIndexStore.from_host_and_port(host=\"0.0.0.0\", port=6379, namespace=\"books-indexstore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=redis_docs, index_store=redis_index, vector_store=chroma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=SimpleDirectoryReader(\"data\").load_data(), \n",
    "    storage_context=storage_context, \n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=448, chunk_overlap=50)\n",
    "    ]\n",
    ")\n",
    "index.set_index_id(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=' Sulla base delle informazioni fornite, Pinocchio sembra essere un burattino che inizialmente viene descritto come un \"ragazzaccio, un vagabondo, un vero rompicollo\" da un vecchietto. Tuttavia, quando il vecchietto chiede direttamente a Pinocchio, che sta fingendo di non conoscersi, quest\\'ultimo lo descrive come \"un gran buon figliuolo, pieno di voglia di studiare, obbediente, affezionato al suo babbo e alla sua famiglia\". Quindi sembra che ci siano descrizioni contrastanti sulla vera natura e personalità di Pinocchio.', source_nodes=[NodeWithScore(node=TextNode(id_='e84243e6-e394-435c-aa25-6e75d248cb75', embedding=None, metadata={'file_path': '/Users/dggallit/Documents/GenAI/personal-projects-and-experiments/notebooks/llama-index-learning/data/pinocchio.txt', 'file_name': 'pinocchio.txt', 'file_type': 'text/plain', 'file_size': 281679, 'creation_date': '2024-02-15', 'last_modified_date': '2024-02-15'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e34ab4b6-68ce-4029-acce-bb25cadfd38b', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/Users/dggallit/Documents/GenAI/personal-projects-and-experiments/notebooks/llama-index-learning/data/pinocchio.txt', 'file_name': 'pinocchio.txt', 'file_type': 'text/plain', 'file_size': 281679, 'creation_date': '2024-02-15', 'last_modified_date': '2024-02-15'}, hash='82b4a84570644087b3a69079346cb0b531c60d85f39e7c3f146effb9ee76201d'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='11d72b84-be09-45f1-87d0-174d3ca300c0', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': '/Users/dggallit/Documents/GenAI/personal-projects-and-experiments/notebooks/llama-index-learning/data/pinocchio.txt', 'file_name': 'pinocchio.txt', 'file_type': 'text/plain', 'file_size': 281679, 'creation_date': '2024-02-15', 'last_modified_date': '2024-02-15'}, hash='4c7282175f6bbbe031b71f1af482106bd2c6c928143403634dfc3132ce94cc71'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='1375a87d-1851-47ee-b84e-a7526676c0e0', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='c698dbc8d6dc934bf7d595814b6943e45b8ccb0185c55a2b518fdfbf988b6644')}, text=\"— interruppe Pinocchio, con gran dolore.\\n\\n— No: ora è vivo, ed è già ritornato a casa sua.\\n\\n   [Illustrazione: — Dite, galantuomo, sapete nulla di un povero\\n   ragazzo ferito nel capo e che si chiamava Eugenio?]\\n\\n— Davvero?... davvero?... — gridò il burattino, saltando\\ndall'allegrezza. — Dunque la ferita non era grave?...\\n\\n— Ma poteva riuscire gravissima e anche mortale, — rispose il\\nvecchietto — perchè gli tirarono nel capo un grosso libro rilegato in\\ncartone.\\n\\n— E chi glielo tirò?\\n\\n— Un suo compagno di scuola: un certo Pinocchio....\\n\\n— E chi è questo Pinocchio? — domandò il burattino facendo lo gnorri.\\n\\n— Dicono che sia un ragazzaccio, un vagabondo, un vero rompicollo.\\n\\n— Calunnie! Tutte calunnie!\\n\\n— Lo conosci tu questo Pinocchio?\\n\\n— Di vista! — rispose il burattino.\\n\\n— E tu, che concetto ne hai? — gli chiese il vecchietto.\\n\\n— A me mi pare un gran buon figliuolo, pieno di voglia di studiare,\\nobbediente, affezionato al suo babbo e alla sua famiglia.... —\\n\\nMentre il burattino sfilava a faccia fresca tutte queste bugie, si\\ntoccò il naso e si accorse che il naso gli era allungato più di un\\npalmo.\", start_char_idx=161191, end_char_idx=162303, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.4771558307268083)], metadata={'e84243e6-e394-435c-aa25-6e75d248cb75': {'file_path': '/Users/dggallit/Documents/GenAI/personal-projects-and-experiments/notebooks/llama-index-learning/data/pinocchio.txt', 'file_name': 'pinocchio.txt', 'file_type': 'text/plain', 'file_size': 281679, 'creation_date': '2024-02-15', 'last_modified_date': '2024-02-15'}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "query_engine.query(\"Chi è Pinocchio?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-vector-stores-opensearch llama-index-readers-elasticsearch -qU\n",
    "%pip install llama-index-storage-docstore-dynamodb llama-index-storage-index-store-dynamodb-store llama-index-storage-kvstore-dynamodb -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# Create the DDB Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.storage.kvstore.dynamodb import DynamoDBKVStore\n",
    "from llama_index.storage.docstore.dynamodb import DynamoDBDocumentStore\n",
    "from llama_index.storage.index_store.dynamodb import DynamoDBIndexStore\n",
    "from llama_index.vector_stores.opensearch import OpensearchVectorStore, OpensearchVectorClient\n",
    "\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=DynamoDBDocumentStore(DynamoDBKVStore.from_table_name(\"books-docstore-table\")), \n",
    "    index_store=DynamoDBIndexStore(DynamoDBKVStore.from_table_name(\"books-index-table\")), \n",
    "    vector_store=OpensearchVectorStore(OpensearchVectorClient(\n",
    "        endpoint=\"XXXXXXXXXXXXXXXXXXXXX\", index=\"books-vector-store\",\n",
    "        embedding_field=\"embedding\", text_field=\"text\",\n",
    "    )),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
