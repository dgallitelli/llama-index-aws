{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Llama-Index and which problems it solves\n",
    "\n",
    "Llama-Index is a system for building retrieval-augmented generation (RAG) applications using large language models (LLMs). It aims to solve common issues with naive RAG systems, such as poor response quality due to bad retrieval, hallucination, and loss of context. Llama-Index improves RAG through better retrieval, filtering, chunking, reranking, and fine-tuning.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h4qoECB8eLEPQchsR5qA5A.gif)\n",
    "\n",
    "Source: [LlamaIndex — Unleashes the power of ChatGPT over your own data](https://sharmadave.medium.com/llama-index-unleashes-the-power-of-chatgpt-over-your-own-data-b67cc2e4e277)\n",
    "\n",
    "## Main components of Llama-Index \n",
    "\n",
    "![](./images/rag-stages.png)\n",
    "\n",
    "There are five key stages within RAG, which in turn will be a part of any larger application you build. Llama-Index provides abstractions and classes for each of these steps. These are:\n",
    "\n",
    "- **Loading**: this refers to getting your data from where it lives – whether it’s text files, PDFs, another website, a database, or an API – into your pipeline. LlamaHub provides hundreds of connectors to choose from.\n",
    "    - **Nodes and Documents**: A `Document` is a container around any data source - for instance, a PDF, an API output, or retrieve data from a database. A `Node` represents a “chunk” of a source Document. *Documents* can be split into *Nodes*.\n",
    "    - **Connectors**: A data connector (often called a `Reader`) ingests data from different data sources and data formats into `Documents` and `Nodes`.\n",
    "- **Indexing**: this means creating a data structure that allows for querying the data. For LLMs this nearly always means creating vector embeddings, numerical representations of the meaning of your data, as well as numerous other metadata strategies to make it easy to accurately find contextually relevant data.\n",
    "    - **Indexes**: format the data into a structure that’s easy to retrieve by generating vector embeddings which are stored in a specialized database called a vector store\n",
    "    - **Embeddings** LLMs generate numerical representations of data called embeddings. When filtering your data for relevance, LlamaIndex will convert queries into embeddings, and your vector store will find data that is numerically similar to the embedding of your query.\n",
    "- **Storing**: once your data is indexed you will almost always want to store your index, as well as other metadata, to avoid having to re-index it.\n",
    "    - A **vector store**: a type of database that is designed to store and handle vector data - a set of coordinates in a multidimensional space which represents mathematically complex data such as images, text, and audio. Vector stores are optimized for operations such as nearest neighbor search, which is a common operation in these applications. In the context of LlamaIndex, the vector store contains the embedding vectors of the ingested document chunks.\n",
    "    - A **document store**, also known as a **document-oriented database**: a type of non-relational database that is designed to store, retrieve, and manage document-oriented information. These documents can be stored in formats such as JSON, XML, BSON, and others. Document stores are optimized for operations such as querying and processing of documents. In the context of LlamaIndex, the document store would contain the actual documents that are being indexed and queried.\n",
    "- **Querying**: for any given indexing strategy there are many ways you can utilize LLMs and LlamaIndex data structures to query, including sub-queries, multi-step queries and hybrid strategies.\n",
    "    - **Retrievers**: A retriever defines how to efficiently retrieve relevant context from an index when given a query. Your retrieval strategy is key to the relevancy of the data retrieved and the efficiency with which it’s done.\n",
    "    - **Routers**: A router determines which retriever will be used to retrieve relevant context from the knowledge base. More specifically, the `RouterRetriever` class, is responsible for selecting one or multiple candidate retrievers to execute a query. They use a selector to choose the best option based on each candidate’s metadata and the query.\n",
    "    - **Node Postprocessors**: A node postprocessor takes in a set of retrieved nodes and applies transformations, filtering, or re-ranking logic to them.\n",
    "    - **Response Synthesizers**: A response synthesizer generates a response from an LLM, using a user query and a given set of retrieved text chunks.\n",
    "- **Evaluation**: a critical step in any pipeline is checking how effective it is relative to other strategies, or when you make changes. Evaluation provides objective measures of how accurate, faithful and fast your responses to queries are.\n",
    "\n",
    "## Integrations with AWS\n",
    "\n",
    "Llama-index integrates with multiple AWS services:\n",
    "1. LLMs and Embeddings Models\n",
    "    - Amazon Bedrock (`pip install llama-index-llms-bedrock`)\n",
    "    - Amazon SageMaker Endpoints (`pip install llama-index-llms-sagemaker-endpoint`)\n",
    "2. Vector Stores\n",
    "    - Amazon OpenSearch (`pip install llama-index-vector-stores-opensearch`)\n",
    "    - Keyspaces for Apache Cassandra (`pip install llama-index-vector-stores-cassandra`)\n",
    "    - Amazon DynamoDB (`pip install llama-index-vector-stores-dynamodb`)\n",
    "    - Postgres (`pip install llama-index-vector-stores-postgres`)\n",
    "    - Redis (`pip install llama-index-vector-stores-redis`)\n",
    "    - Any self-hosted database ☺️️\n",
    "\n",
    "## How to get started\n",
    "You can get started with Llama-Index in just a few lines of code. The key steps are:\n",
    "\n",
    "1. Ingest your data into a vector database \n",
    "2. Index your data for retrieval\n",
    "3. Load a LLM\n",
    "4. Query over the data by retrieving chunks and synthesizing with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index (from -r requirements.txt (line 1))\n",
      "  Using cached llama_index-0.10.30-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-llms-sagemaker-endpoint (from -r requirements.txt (line 2))\n",
      "  Using cached llama_index_llms_sagemaker_endpoint-0.1.3-py3-none-any.whl.metadata (731 bytes)\n",
      "Collecting llama-index-embeddings-sagemaker-endpoint (from -r requirements.txt (line 3))\n",
      "  Using cached llama_index_embeddings_sagemaker_endpoint-0.1.3-py3-none-any.whl.metadata (690 bytes)\n",
      "Collecting llama-index-llms-bedrock (from -r requirements.txt (line 4))\n",
      "  Using cached llama_index_llms_bedrock-0.1.6-py3-none-any.whl.metadata (687 bytes)\n",
      "Collecting llama-index-embeddings-bedrock (from -r requirements.txt (line 5))\n",
      "  Using cached llama_index_embeddings_bedrock-0.1.4-py3-none-any.whl.metadata (646 bytes)\n",
      "Collecting sagemaker (from -r requirements.txt (line 6))\n",
      "  Using cached sagemaker-2.216.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting boto3 (from -r requirements.txt (line 7))\n",
      "  Using cached boto3-1.34.88-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore (from -r requirements.txt (line 8))\n",
      "  Using cached botocore-1.34.88-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting faiss-cpu (from -r requirements.txt (line 9))\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting chromadb (from -r requirements.txt (line 10))\n",
      "  Using cached chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.30 (from llama-index->-r requirements.txt (line 1))\n",
      "  Using cached llama_index_core-0.10.30-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_index_embeddings_openai-0.1.8-py3-none-any.whl.metadata (603 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index->-r requirements.txt (line 1))\n",
      "  Using cached llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index->-r requirements.txt (line 1))\n",
      "  Using cached llama_index_llms_openai-0.1.16-py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_index_program_openai-0.1.5-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index->-r requirements.txt (line 1))\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_index_readers_file-0.1.19-py3-none-any.whl.metadata (979 bytes)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-index-llms-llama-cpp<0.2.0,>=0.1.1 (from llama-index-llms-sagemaker-endpoint->-r requirements.txt (line 2))\n",
      "  Using cached llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl.metadata (695 bytes)\n",
      "Collecting llama-index-llms-anthropic<0.2.0,>=0.1.7 (from llama-index-llms-bedrock->-r requirements.txt (line 4))\n",
      "  Using cached llama_index_llms_anthropic-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting attrs<24,>=23.1.0 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting google-pasta (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting numpy<2.0,>=1.9.0 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting protobuf<5.0,>=3.12 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 6)) (24.0)\n",
      "Collecting pandas (from sagemaker->-r requirements.txt (line 6))\n",
      "  Downloading pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting pathos (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting schema (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting PyYAML~=6.0 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 6)) (4.2.0)\n",
      "Collecting tblib<4,>=1.7.0 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting urllib3<3.0.0,>=1.26.8 (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting requests (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting docker (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting tqdm (from sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from sagemaker->-r requirements.txt (line 6)) (5.9.8)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r requirements.txt (line 7))\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r requirements.txt (line 7))\n",
      "  Using cached s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.venv/lib/python3.11/site-packages (from botocore->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Collecting build>=1.0.3 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pydantic>=1.9 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting chroma-hnswlib==0.7.3 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading fastapi-0.110.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.11/site-packages (from chromadb->-r requirements.txt (line 10)) (4.11.0)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading onnxruntime-1.17.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.4 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb->-r requirements.txt (line 10))\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Collecting overrides>=7.3.1 (from chromadb->-r requirements.txt (line 10))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading grpcio-1.62.2-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb->-r requirements.txt (line 10))\n",
      "  Using cached bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb->-r requirements.txt (line 10))\n",
      "  Using cached kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb->-r requirements.txt (line 10))\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb->-r requirements.txt (line 10))\n",
      "  Downloading orjson-3.10.1-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyproject_hooks (from build>=1.0.3->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=1.4.0->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting certifi>=14.05.14 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10)) (1.16.0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index->-r requirements.txt (line 1))\n",
      "  Downloading openai-1.23.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Downloading SQLAlchemy-2.0.29-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached llamaindex_py_client-0.1.18-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1)) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting anthropic<0.24.0,>=0.23.1 (from llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock->-r requirements.txt (line 4))\n",
      "  Using cached anthropic-0.23.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting llama-cpp-python<0.3.0,>=0.2.32 (from llama-index-llms-llama-cpp<0.2.0,>=0.1.1->llama-index-llms-sagemaker-endpoint->-r requirements.txt (line 2))\n",
      "  Downloading llama_cpp_python-0.2.63.tar.gz (37.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index->-r requirements.txt (line 1))\n",
      "  Downloading llama_parse-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 10)) (69.2.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.9->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic>=1.9->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading pydantic_core-2.18.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->sagemaker->-r requirements.txt (line 6))\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 10))\n",
      "  Downloading websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached rpds_py-0.18.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting ppft>=1.7.6.8 (from pathos->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dill>=0.3.8 (from pathos->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pox>=0.3.4 (from pathos->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting multiprocess>=0.70.16 (from pathos->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting contextlib2>=0.5.5 (from schema->sagemaker->-r requirements.txt (line 6))\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock->-r requirements.txt (line 4))\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock->-r requirements.txt (line 4))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from anthropic<0.24.0,>=0.23.1->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock->-r requirements.txt (line 4))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp<0.2.0,>=0.1.1->llama-index-llms-sagemaker-endpoint->-r requirements.txt (line 2))\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp<0.2.0,>=0.1.1->llama-index-llms-sagemaker-endpoint->-r requirements.txt (line 2))\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Downloading regex-2024.4.16-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 10)) (2.17.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.30->llama-index->-r requirements.txt (line 1))\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python<0.3.0,>=0.2.32->llama-index-llms-llama-cpp<0.2.0,>=0.1.1->llama-index-llms-sagemaker-endpoint->-r requirements.txt (line 2))\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 10))\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Using cached llama_index-0.10.30-py3-none-any.whl (6.9 kB)\n",
      "Using cached llama_index_llms_sagemaker_endpoint-0.1.3-py3-none-any.whl (4.8 kB)\n",
      "Using cached llama_index_embeddings_sagemaker_endpoint-0.1.3-py3-none-any.whl (4.2 kB)\n",
      "Using cached llama_index_llms_bedrock-0.1.6-py3-none-any.whl (8.2 kB)\n",
      "Using cached llama_index_embeddings_bedrock-0.1.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached sagemaker-2.216.0-py3-none-any.whl (1.5 MB)\n",
      "Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Using cached smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Using cached boto3-1.34.88-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.34.88-py3-none-any.whl (12.2 MB)\n",
      "Downloading faiss_cpu-1.8.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "Downloading chroma_hnswlib-0.7.3-cp311-cp311-macosx_11_0_arm64.whl (198 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.7/198.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl (528 kB)\n",
      "Downloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading fastapi-0.110.2-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.2-cp311-cp311-macosx_10_10_universal2.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm01\u001b[0m\n",
      "\u001b[?25hUsing cached importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
      "Using cached llama_index_core-0.10.30-py3-none-any.whl (15.4 MB)\n",
      "Downloading llama_index_embeddings_openai-0.1.8-py3-none-any.whl (6.0 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl (6.7 kB)\n",
      "Using cached llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "Using cached llama_index_llms_anthropic-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Using cached llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl (5.1 kB)\n",
      "Using cached llama_index_llms_openai-0.1.16-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\n",
      "Downloading llama_index_program_openai-0.1.5-py3-none-any.whl (4.1 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.19-py3-none-any.whl (36 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading mmh3-4.1.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading onnxruntime-1.17.3-cp311-cp311-macosx_11_0_universal2.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.1-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (250 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.6/250.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading pulsar_client-3.5.0-cp311-cp311-macosx_10_15_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.9/407.9 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.1-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "Downloading pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "Using cached schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl (390 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.2/390.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached anthropic-0.23.1-py3-none-any.whl (869 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl (145 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.9/145.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading llama_parse-0.4.1-py3-none-any.whl (7.3 kB)\n",
      "Using cached llamaindex_py_client-0.1.18-py3-none-any.whl (136 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Using cached pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "Using cached ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached rpds_py-0.18.0-cp311-cp311-macosx_11_0_arm64.whl (330 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading SQLAlchemy-2.0.29-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached tiktoken-0.6.0-cp311-cp311-macosx_11_0_arm64.whl (949 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading uvloop-0.19.0-cp311-cp311-macosx_10_9_universal2.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp311-cp311-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.2/418.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-12.0-cp311-cp311-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "Using cached greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.4.16-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)\n",
      "Downloading filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Using cached joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.63-cp311-cp311-macosx_14_0_arm64.whl size=3090022 sha256=8039658ea261fb567f10b5a1ee55f846a4c15bf20bcfe3a89b91cf3a4b01e533\n",
      "  Stored in directory: /Users/dggallit/Library/Caches/pip/wheels/56/98/c9/dd61ab5325a2bd3e1d271afb8d7d1e7d2ed10fa39b8c9bf63f\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: striprtf, pytz, pypika, mpmath, monotonic, mmh3, flatbuffers, dirtyjson, zipp, wrapt, websockets, websocket-client, uvloop, urllib3, tzdata, tqdm, tenacity, tblib, sympy, SQLAlchemy, soupsieve, sniffio, smdebug-rulesconfig, shellingham, rpds-py, regex, PyYAML, python-dotenv, pyproject_hooks, pypdf, pydantic-core, pyasn1, protobuf, ppft, pox, pillow, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, numpy, networkx, mypy-extensions, multidict, mdurl, marshmallow, MarkupSafe, joblib, jmespath, importlib-resources, idna, humanfriendly, httptools, h11, grpcio, greenlet, google-pasta, fsspec, frozenlist, filelock, distro, diskcache, dill, contextlib2, cloudpickle, click, charset-normalizer, certifi, cachetools, bcrypt, backoff, attrs, asgiref, annotated-types, yarl, uvicorn, typing-inspect, schema, rsa, requests, referencing, pydantic, pyasn1-modules, pulsar-client, pandas, opentelemetry-proto, nltk, multiprocess, markdown-it-py, jinja2, importlib-metadata, httpcore, googleapis-common-protos, faiss-cpu, deprecated, coloredlogs, chroma-hnswlib, build, botocore, beautifulsoup4, anyio, aiosignal, watchfiles, tiktoken, starlette, s3transfer, rich, requests-oauthlib, posthog, pathos, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, llama-cpp-python, jsonschema-specifications, huggingface-hub, httpx, google-auth, docker, dataclasses-json, aiohttp, typer, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, openai, llamaindex-py-client, kubernetes, jsonschema, fastapi, boto3, sagemaker, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, llama-index-legacy, llama-index-core, anthropic, opentelemetry-instrumentation-fastapi, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-llama-cpp, llama-index-llms-anthropic, llama-index-indices-managed-llama-cloud, llama-index-embeddings-sagemaker-endpoint, llama-index-embeddings-openai, llama-index-embeddings-bedrock, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-sagemaker-endpoint, llama-index-llms-bedrock, llama-index-cli, llama-index-agent-openai, chromadb, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed MarkupSafe-2.1.5 PyYAML-6.0.1 SQLAlchemy-2.0.29 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 anthropic-0.23.1 anyio-4.3.0 asgiref-3.8.1 attrs-23.2.0 backoff-2.2.1 bcrypt-4.1.2 beautifulsoup4-4.12.3 boto3-1.34.88 botocore-1.34.88 build-1.2.1 cachetools-5.3.3 certifi-2024.2.2 charset-normalizer-3.3.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 click-8.1.7 cloudpickle-2.2.1 coloredlogs-15.0.1 contextlib2-21.6.0 dataclasses-json-0.6.4 deprecated-1.2.14 dill-0.3.8 dirtyjson-1.0.8 diskcache-5.6.3 distro-1.9.0 docker-7.0.0 faiss-cpu-1.8.0 fastapi-0.110.2 filelock-3.13.4 flatbuffers-24.3.25 frozenlist-1.4.1 fsspec-2024.3.1 google-auth-2.29.0 google-pasta-0.2.0 googleapis-common-protos-1.63.0 greenlet-3.0.3 grpcio-1.62.2 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.22.2 humanfriendly-10.0 idna-3.7 importlib-metadata-6.11.0 importlib-resources-6.4.0 jinja2-3.1.3 jmespath-1.0.1 joblib-1.4.0 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 kubernetes-29.0.0 llama-cpp-python-0.2.63 llama-index-0.10.30 llama-index-agent-openai-0.2.2 llama-index-cli-0.1.12 llama-index-core-0.10.30 llama-index-embeddings-bedrock-0.1.4 llama-index-embeddings-openai-0.1.8 llama-index-embeddings-sagemaker-endpoint-0.1.3 llama-index-indices-managed-llama-cloud-0.1.5 llama-index-legacy-0.9.48 llama-index-llms-anthropic-0.1.10 llama-index-llms-bedrock-0.1.6 llama-index-llms-llama-cpp-0.1.3 llama-index-llms-openai-0.1.16 llama-index-llms-sagemaker-endpoint-0.1.3 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.5 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.19 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.1 llamaindex-py-client-0.1.18 markdown-it-py-3.0.0 marshmallow-3.21.1 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.0.5 multiprocess-0.70.16 mypy-extensions-1.0.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.17.3 openai-1.23.2 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.1 overrides-7.7.0 pandas-2.2.2 pathos-0.3.2 pillow-10.3.0 posthog-3.5.0 pox-0.3.4 ppft-1.7.6.8 protobuf-4.25.3 pulsar-client-3.5.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pydantic-2.7.0 pydantic-core-2.18.1 pypdf-4.2.0 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.1 pytz-2024.1 referencing-0.34.0 regex-2024.4.16 requests-2.31.0 requests-oauthlib-2.0.0 rich-13.7.1 rpds-py-0.18.0 rsa-4.9 s3transfer-0.10.1 sagemaker-2.216.0 schema-0.7.5 shellingham-1.5.4 smdebug-rulesconfig-1.0.1 sniffio-1.3.1 soupsieve-2.5 starlette-0.37.2 striprtf-0.0.26 sympy-1.12 tblib-3.0.0 tenacity-8.2.3 tiktoken-0.6.0 tokenizers-0.19.1 tqdm-4.66.2 typer-0.12.3 typing-inspect-0.9.0 tzdata-2024.1 urllib3-2.2.1 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websocket-client-1.7.0 websockets-12.0 wrapt-1.16.0 yarl-1.9.4 zipp-3.18.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
